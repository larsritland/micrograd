{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brew install graphviz\n",
    "#%pip install graphviz\n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root, format='svg', rankdir='LR'):\n",
    "    \"\"\"\n",
    "    format: png | svg | ...\n",
    "    rankdir: TB (top to bottom graph) | LR (left to right)\n",
    "    \"\"\"\n",
    "    assert rankdir in ['LR', 'TB']\n",
    "    nodes, edges = trace(root)\n",
    "    dot = Digraph(format=format, graph_attr={'rankdir': rankdir}) #, node_attr={'rankdir': 'TB'})\n",
    "    \n",
    "    for n in nodes:\n",
    "        dot.node(name=str(id(n)), label = \"{ data %.4f | grad %.4f }\" % (n.data, n.grad), shape='record')\n",
    "        if n._op:\n",
    "            dot.node(name=str(id(n)) + n._op, label=n._op)\n",
    "            dot.edge(str(id(n)) + n._op, str(id(n)))\n",
    "    \n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a very simple example\n",
    "x = Value(1.0)\n",
    "y = (x * 2 + 1).relu()\n",
    "y.backward()\n",
    "#draw_dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple 2D neuron\n",
    "import random\n",
    "from micrograd import nn\n",
    "\n",
    "random.seed(1337)\n",
    "n = nn.Neuron(2)\n",
    "x = [Value(1.0), Value(-2.0)]\n",
    "y = n(x)\n",
    "y.backward()\n",
    "\n",
    "#dot = draw_dot(y)\n",
    "#dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.nn import MLP\n",
    "n = MLP(3,[4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "    [2.0, 3.0,-1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0,1.0],\n",
    "    [1.0, 1.0,-1.0]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n",
    "ypred = [n(x) for x in xs]\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot.render('gout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training av very simple model: y = wx + b\n",
    "Using micrograd MLP and a dataset of 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a 1-layer MLP and setting its parameters\n",
    "n = MLP(1,[1])   # 1 input, 1 output, y = wx + b\n",
    "params = n.parameters()\n",
    "params[0].data = 1.9\n",
    "params[1].data = 2.1\n",
    "for p in params:\n",
    "    print(p.data)\n",
    "print(n)\n",
    "\n",
    "# Loading the dataset consisting 2 samples\n",
    "xs = [[2.0],\n",
    "      [3.0]]\n",
    "ys = [6.0,8.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions\n",
    "ypred = [n(x) for x in xs]\n",
    "print([yp.data for yp in ypred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss\n",
    "loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.zero_grad()\n",
    "loss.backward()\n",
    "learning_rate = 0.01\n",
    "for p in n.parameters():\n",
    "    p.data -= p.grad * learning_rate\n",
    "    print(p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "    n.zero_grad()\n",
    "    loss.backward()\n",
    "    for p in n.parameters():\n",
    "        p.data -= p.grad * learning_rate\n",
    "    if i % 1000 == 0:\n",
    "        print(loss, params[0].data, params[1].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training av very simple model: y = wx + b\n",
    "Using micrograd and a dataset of 2 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "x = [[Value(2.0)],\n",
    "     [Value(3.0)]]\n",
    "y = [Value(6.0),\n",
    "     Value(8.0)]\n",
    "\n",
    "# Weights initialization\n",
    "w = [Value(1.9)]\n",
    "b = Value(2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypred = [sum((wi*xi for wi,xi in zip(w, xt)), b) for xt in x]\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss\n",
    "loss = sum((yout - ygt)**2 for ygt, yout in zip(y, ypred))\n",
    "print(f'loss: {loss.data} | grad: {loss.grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset gradients\n",
    "for wi in w:\n",
    "    wi.grad = 0\n",
    "b.grad = 0\n",
    "\n",
    "# Backpropagation - calculating gradients\n",
    "loss.backward()\n",
    "\n",
    "# Updating weights\n",
    "learning_rate = 0.01\n",
    "for wi in w:\n",
    "    wi.data -= wi.grad * learning_rate\n",
    "b.data -= b.grad * learning_rate\n",
    "print(f'w:{[wi.data for wi in w]}, b:{b.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    ypred = [sum((wi*xi for wi,xi in zip(w, xt)), b) for xt in x]\n",
    "    loss = sum((yout - ygt)**2 for ygt, yout in zip(y, ypred))\n",
    "    for wi in w:\n",
    "        wi.grad = 0\n",
    "    b.grad = 0\n",
    "    loss.backward()\n",
    "    for wi in w:\n",
    "        wi.data -= wi.grad * learning_rate\n",
    "    b.data -= b.grad * learning_rate\n",
    "    if i % 100 == 0:\n",
    "        print(f'loss: {loss.data} w:{[wi.data for wi in w]}, b:{b.data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
